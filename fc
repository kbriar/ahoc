import numpy as np
from numpy import False_
import networkx as nx
import pandas as pd
import warnings
import datetime, pytz
from google.colab import auth
from google.auth import default
from colabtools import f1

# Set up SQL data importer
warnings.filterwarnings('ignore')
ganpati_group = 'svct-ops-access'
f1.set_accounting_group(ganpati_group)

df = f1.Execute('''
SELECT
    driving_hub_id as hub_id,
    fprint,
    u,
    v,
    weight_
FROM ambarishmohan.categorize_chain
''')

class sv_graph:
    """
    Builds a weighted graph per hub and extracts cluster info.
    """
    current_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))

    def __init__(self, data):
        self.data = data.copy()
        # ensure proper types
        self.data['u']       = self.data['u'].astype(str)
        self.data['v']       = self.data['v'].astype(str)
        self.data['weight_'] = self.data['weight_'].astype(float)
        self.hub_id = self.data.iloc[0]['hub_id']

    def graph_generator(self):
        edges = list(zip(self.data['u'], self.data['v'], self.data['weight_']))
        G = nx.Graph()
        G.add_weighted_edges_from(edges)
        return G

    def cluster_classi(self, km):
        if km >= 10:
            return 'C1'
        if 3 < km < 10:
            return 'C2'
        return 'C3'

    def components_connected(self):
        return list(nx.connected_components(self.graph_generator()))

    def cc_info(self):
        rows = []
        G = self.graph_generator()
        for cid, comp in enumerate(self.components_connected(), start=1):
            sub = G.subgraph(comp)
            size_km = round(sub.size(weight='weight')/1000, 2)
            cls = self.cluster_classi(size_km)
            details = []
            for u, v, w in sub.edges(data='weight'):
                mask = ((self.data['u'] == u) & (self.data['v'] == v)) |
                       ((self.data['u'] == v) & (self.data['v'] == u))
                fps = self.data.loc[mask, 'fprint'].unique()
                for fpt in fps:
                    details.append((u, v, w, fpt))
            rows.append({
                'hub_id':        self.hub_id,
                'cluster_id':    cid,
                'cluster_classi':cls,
                'size':          size_km,
                'edges':         sub.number_of_edges(),
                'nodes':         sub.number_of_nodes(),
                'chain_test':    'Yes' if max(dict(sub.degree()).values()) == 2 else 'No',
                'temp_sub_graph':list(comp),
                'details':       details
            })
        return pd.DataFrame(rows)

    def framer(self, sums, counts, full_cc):
        country = self.hub_id.split('-')[1].split('.')[0]
        frame = [self.hub_id, country]
        # total kms and component counts
        for cls in ['C1','C2','C3']:
            frame.append(round(sums.get(cls, 0), 2))
        for cls in ['C1','C2','C3']:
            frame.append(int(counts.get(cls, 0)))
        # collect segment lists per class
        for cls in ['C1','C2','C3']:
            segs = {(u, v)
                    for _, row in full_cc[full_cc.cluster_classi == cls].iterrows()
                    for (u, v, w, f) in row.details}
            frame.append(list(segs))
        return frame

    def cc_output_info(self):
        temp = self.cc_info()
        sums = temp.groupby('cluster_classi')['size'].sum()
        counts = temp.groupby('cluster_classi')['size'].count()
        return self.framer(sums, counts, temp)

    def cc_info_detail(self):
        temp = self.cc_info()
        gb = temp.groupby(['nodes', 'cluster_classi'])['size'].sum()
        return pd.DataFrame(gb)

class Inititiator:
    """
    Orchestrates sv_graph across all hubs and outputs summary and details.
    """
    def __init__(self, df):
        self.file = df.copy()

    def hub_selector_list(self):
        return list(self.file['hub_id'].unique())

    def filter(self):
        return [sv_graph(self.file[self.file['hub_id'] == hub]).cc_output_info()
                for hub in self.hub_selector_list()]

    def main_data_df(self):
        data = self.filter()
        cols = [
            'hub_id','country_code',
            'C1_kms','C2_kms','C3_kms',
            'C1_count','C2_count','C3_count',
            'C1_segments','C2_segments','C3_segments'
        ]
        return pd.DataFrame(data, columns=cols)

    def details_df(self):
        rows = []
        for hub in self.hub_selector_list():
            cc = sv_graph(self.file[self.file['hub_id'] == hub]).cc_info()
            for _, rec in cc.iterrows():
                for u, v, w, fpt in rec['details']:
                    rows.append({
                        'hub_id':        rec['hub_id'],
                        'cluster_classi':rec['cluster_classi'],
                        'u':             u,
                        'v':             v,
                        'weight':        w,
                        'fprint':        fpt
                    })
        return pd.DataFrame(rows)

    def export_to_csv(self, summary_path='hub_summary.csv', details_path='hub_details.csv'):
        self.main_data_df().to_csv(summary_path, index=False)
        self.details_df().to_csv(details_path, index=False)
        return summary_path, details_path

# Execute and write CSVs
I1 = Inititiator(df)
summary_csv, details_csv = I1.export_to_csv()
print('Written:', summary_csv, details_csv)
