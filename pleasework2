import pandas as pd
import networkx as nx

class sv_graph:
    def __init__(self, data):
        self.data   = data.copy()
        self.hub_id = self.data.iloc[0, 0]

    def graph_generator(self):
        G = nx.Graph()
        for _, row in self.data.iterrows():
            u = str(row.u)
            v = str(row.v)
            w = float(row.weight_)
            G.add_edge(u, v, weight=w)
        return G

    def cluster_classi(self, km):
        if km >= 10:      return "C1"
        if 3 < km < 10:   return "C2"
        return "C3"

    def cc_info(self):
        G     = self.graph_generator()
        comps = list(nx.connected_components(G))
        rows  = []

        for cid, nodes in enumerate(comps, start=1):
            sub      = G.subgraph(nodes)
            size_km  = round(sub.size(weight="weight") / 1000, 2)
            cls      = self.cluster_classi(size_km)
            chain    = "Yes" if max(dict(sub.degree()).values()) == 2 else "No"

            # gather (u, v, weight, fprint) tuples for every edge & fingerprint
            details = []
            for u, v, w in sub.edges(data="weight"):
                mask = (
                    ((self.data.u.astype(str) == u) & (self.data.v.astype(str) == v)) |
                    ((self.data.u.astype(str) == v) & (self.data.v.astype(str) == u))
                )
                fps = (
                    self.data.loc[mask, ["fprint", "weight_"]]
                    .drop_duplicates()
                    .itertuples(index=False, name=None)
                )
                for fpt, wt in fps:
                    details.append((u, v, float(w), fpt))

            rows.append({
                "hub_id":         self.hub_id,
                "cluster_id":     cid,
                "cluster_classi": cls,
                "size_km":        size_km,
                "edge_count":     sub.number_of_edges(),
                "node_count":     sub.number_of_nodes(),
                "chain_test":     chain,
                "details":        details
            })

        return pd.DataFrame(rows)


class Initiator:
    def __init__(self, df):
        # rename and cast
        self.df = df.rename(columns={"driving_hub_id": "hub_id"})
        self.df.u      = self.df.u.astype(str)
        self.df.v      = self.df.v.astype(str)
        self.df.weight_= self.df.weight_.astype(float)

    def summary_df(self):
        # collect all component-info tables
        cc_list = []
        for hub in self.df.hub_id.unique():
            sg = sv_graph(self.df[self.df.hub_id == hub])
            cc_list.append(sg.cc_info())
        df_cc = pd.concat(cc_list, ignore_index=True)

        rows = []
        for hub, grp in df_cc.groupby("hub_id"):
            # extract 2-letter country code from hub_id
            country = hub.split("-")[1].split(".")[0]
            row = {"hub_id": hub, "country_code": country}

            for cls in ["C1", "C2", "C3"]:
                sub = grp[grp.cluster_classi == cls]

                # Safely sum size_km and count clusters
                row[f"{cls}_kms"] = sub["size_km"].sum() if not sub.empty else 0
                row[f"{cls}_count"] = sub["cluster_id"].count() if not sub.empty else 0

                # --- segment lists: unique (u, v, weight) tuples ---
                segs = {
                    (u, v, w)
                    for detail in sub.details
                    for (u, v, w, f) in detail
                } if not sub.empty else set()
                row[f"{cls}_segments"] = list(segs)

                # --- fingerprints: count + list of (fprint, weight) ---
                fp2w = {}
                if not sub.empty:
                    for detail in sub.details:
                        for (u, v, w, f) in detail:
                            fp2w[f] = w
                row[f"{cls}_no_of_fprint"] = len(fp2w)
                row[f"{cls}_list_of_fprints"] = list(fp2w.items())

            rows.append(row)

        return pd.DataFrame(rows)

    def details_df(self):
        rows = []
        for hub in self.df.hub_id.unique():
            sg  = sv_graph(self.df[self.df.hub_id == hub])
            cc  = sg.cc_info()
            country = hub.split("-")[1].split(".")[0]

            for _, rec in cc.iterrows():
                for (u, v, w, fpt) in rec.details:
                    rows.append({
                        "hub_id":         rec.hub_id,
                        "country_code":   country,
                        "cluster_classi": rec.cluster_classi,
                        "u":               u,
                        "v":               v,
                        "weight":         w,
                        "fprint":         fpt
                    })

        return pd.DataFrame(rows)

    def export_to_excel(self, path="hub_summary.xlsx"):
        s = self.summary_df()
        d = self.details_df()
        with pd.ExcelWriter(path, engine="xlsxwriter") as writer:
            s.to_excel(writer, sheet_name="Summary", index=False)
            d.to_excel(writer, sheet_name="Details", index=False)
        return path


# --- USAGE ---
# df = pd.read_csv("hub_data.csv")  # or however you load it
# I = Initiator(df)
# file_path = I.export_to_excel("output.xlsx")
# print("Wrote:", file_path)
#
# # Then you can use your Colab downloader:
# from colabtools import fileedit
# fileedit.download_file(file_path)
